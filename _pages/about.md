---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Howdy!

I'm a second year PhD student in the Computer Science Department of **UT Austin**. I'm fortunate to be advised by Prof. **Inderjit Dhillon** and Prof. **Sujay Sanghavi**. Broadly, I'm interested in the design of efficient and provable machine learning and deep learning algorithms. Specifically, my current research interests include large-scale optimization, federated learning, and machine learning theory.

Previously, I was a dual degree (combined bachelor's and master's degree) student in the Department of Electrical Engineering, **Indian Institute of Technology** (**IIT**) **Bombay**. At IIT Bombay, I've worked under the guidance of Prof. **Subhasis Chaudhuri** on some probabilistically provable theoretical aspects of neural networks and algorithmic aspects of large-scale optimization for my final thesis <a href="https://drive.google.com/open?id=1gOwSCWhbJLVFN2K178Ujve-WxFv_VDdB">[link]</a>. I was awarded the **Undergraduate Research Award** (URA-03) for exceptional work in my final thesis.

You can check out my CV [here]({{ site.url }}/assets/CV_2020.pdf).

**Update**: I'll be interning at **Google Research** this summer, working on federated learning with Zheng Xu, Satyen Kale and Tong Zhang.

**<font size="+3">Publications & Competitions</font>**

* "**Faster Non-Convex Federated Learning via Global and Local Momentum**" - **Rudrajit Das**, Anish Acharya, Abolfazl Hashemi, Sujay Sanghavi, Inderjit S. Dhillon, Ufuk Topcu.

    Pre-print. Download paper <a href="https://arxiv.org/pdf/2012.04061.pdf" style="color: #0000FF">here</a>.

* "**On the Benefits of Multiple Gossip Steps in Communication-Constrained Decentralized Optimization**" - Abolfazl Hashemi, Anish Acharya^, **Rudrajit Das**^, Haris Vikalo, Sujay Sanghavi, Inderjit Dhillon (^ denotes equal contribution).

    Pre-print. Download paper <a href="https://arxiv.org/pdf/2011.10643.pdf" style="color: #0000FF">here</a>.
    
* "**On the Convergence of a Biased Version of Stochastic Gradient Descent**" - **Rudrajit Das**, Jiong Zhang and Inderjit Dhillon.

    Accepted for poster presentation in "Beyond First Order Methods in ML" workshop in NeurIPS 2019. Download paper <a href="https://drive.google.com/file/d/1fn1iO_CXWJzgVqiY3p84NfCf__i6hKCW/view" style="color: #0000FF">here</a>.

* "**On the Separability of Classes with the Cross-Entropy Loss Function**" - **Rudrajit Das** and Subhasis Chaudhuri.

    Pre-print. Download paper <a href="https://arxiv.org/abs/1909.06930" style="color: #0000FF">here</a>.
    
* "**Nonlinear Blind Compressed Sensing under Signal-Dependent Noise**" - **Rudrajit Das** and Ajit Rajwade.

    Accepted for presentation in IEEE International Conference on Image Processing (ICIP) 2019. Download paper <a href="https://ieeexplore.ieee.org/abstract/document/8803173" style="color: #0000FF">here</a>.

* "**Sparse Kernel PCA for Outlier Detection**" - **Rudrajit Das**, Aditya Golatkar and Suyash Awate.

    Accepted for oral presentation in IEEE International Conference on Machine Learning and Applications (ICMLA) 2018. Download paper <a href="https://arxiv.org/abs/1809.02497" style="color: #0000FF">here</a>.

* **iFood Challenge, FGVC Workshop, CVPR 2018** - Parth Kothari^, Arka Sadhu^, Aditya Golatkar^, **Rudrajit Das**^ (^ denotes equal contribution).

    Finished $2^{nd}$ in the public leaderboard and $3^{rd}$ in the private leaderboard (Team name : Invincibles). <a href="https://www.kaggle.com/c/ifood2018/leaderboard" style="color: #0000FF">Leaderboard Link</a>.
    Invited to present our method at CVPR 2018 (slides can be found  <a href="https://drive.google.com/file/d/1ycgDwlw62mWgaLy5qslvqjyiND0vgYTG/view?usp=sharing" style="color: #0000FF">here</a>).

**<font size="+3">Internships</font>**

* **Applied Scientist Intern at Amazon Search (Virtual), Berkeley, USA** (May '20 - Aug '20) <br/>
    *Mentor: Dan Hill, Manager: Sujay Sanghavi* <br/>
    * Worked on customer-specific query correction by leveraging the "session data" (i.e. previous searches of the customer) using SOTA Transformer models. Our model generated better candidates than the production system. <br/>

* **Institute for Biomechanics, ETH Zürich, Switzerland** (May '17 - July '17) <br/>
    *Guide : Dr. Patrik Christen and Prof. Dr. Ralph Müller, D-HEST* <br/>
    * Proposed a stable linear model (with closed form solution) and a fuzzy boolean network for bone re-modeling. Also developed an automated 2D-3D image registration framework for histology images from scratch. <br/>
    
* **Altisource Business Solutions Private Limited, Bengaluru, India** (May '16 - July '16) <br/>
    * Developed a notification system using Pagerduty, a popular incident management software, and worked on the UI of the company’s monitoring dashboard built using JBoss Dashbuilder. <br/>
      
I was also one of the very few undergraduates selected to attend the **PRAIRIE Artificial Intelligence Summer School** (<a href="https://project.inria.fr/paiss/" style="color: #0000FF">**PAISS**</a>) co-organized by Inria and NAVER LABS Europe in Grenoble, France during July 2018. Here I presented a poster (can be found <a href="https://github.com/rudrajit15/Existence-of-sparse-basis-for-deep-learning-kernels/blob/master/Inria_poster.pdf" style="color: #0000FF">here</a>) titled “**Existence of Sparse Basis for Deep Learning Kernels?**”.
